{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19a29d20b88>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./all_data/train_data_11_15.csv', encoding='utf-8-sig')\n",
    "test_data = pd.read_csv('./all_data/test_data_11_15.csv', encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "train_data.score.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15455</th>\n",
       "      <td>예약이 어렵다는 마렘마 운좋게 당일 6시 예약! 그러나 ㅋㅋ1시간 시간제한이 있었어...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15456</th>\n",
       "      <td>마카롱이 쪽득쫀득하고 맛있는곳</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15457</th>\n",
       "      <td>음식은 괜츈하지만 환기가 전혀안됨\\n음식먹다 질식할뻔, 쾌적함에 민감한 사람은 근처...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15458</th>\n",
       "      <td>그러나 맛과 분위기에 빠져들다 보면 가격이 비싼것도 무마되는곳입니다 ㅎㅎ 자주 방문...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15459</th>\n",
       "      <td>개인적으로 엔제리너스 커피 음... 서울역에 카페가 항상 만석이라서ㅜ 엔제리너스 역...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  score\n",
       "15455  예약이 어렵다는 마렘마 운좋게 당일 6시 예약! 그러나 ㅋㅋ1시간 시간제한이 있었어...      0\n",
       "15456                                   마카롱이 쪽득쫀득하고 맛있는곳      0\n",
       "15457  음식은 괜츈하지만 환기가 전혀안됨\\n음식먹다 질식할뻔, 쾌적함에 민감한 사람은 근처...      0\n",
       "15458  그러나 맛과 분위기에 빠져들다 보면 가격이 비싼것도 무마되는곳입니다 ㅎㅎ 자주 방문...      1\n",
       "15459  개인적으로 엔제리너스 커피 음... 서울역에 카페가 항상 만석이라서ㅜ 엔제리너스 역...      0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15460, 2)\n",
      "(1718, 2)\n",
      "15460\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "print(train_data['review'].size)\n",
    "print(test_data['review'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>과카몰리 프라이즈 / 더블 더블 버거 / 아보카도 버거</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahhhh 별로임 피스타치오랑 에스프레소 였나 뭐 먹었는데 걍 그저그럼 식감도 그...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼선이라고 붙은 메뉴들은 맛이 나쁘지 않지만 가격이 비싼 편이고, 일반 짜장면이나 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 지점 은 별로 붐비지 않아서 좋고 커피 보다는 다른 차와 간단한 스낵류가 개인적...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>음식도 깔끔하고 인테리어도 잘되어 있음. 맛이 있으며, 가격대비 상당히 만족스러운 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0                     과카몰리 프라이즈 / 더블 더블 버거 / 아보카도 버거      0\n",
       "1  Nahhhh 별로임 피스타치오랑 에스프레소 였나 뭐 먹었는데 걍 그저그럼 식감도 그...      0\n",
       "2  삼선이라고 붙은 메뉴들은 맛이 나쁘지 않지만 가격이 비싼 편이고, 일반 짜장면이나 ...      0\n",
       "3  이 지점 은 별로 붐비지 않아서 좋고 커피 보다는 다른 차와 간단한 스낵류가 개인적...      1\n",
       "4  음식도 깔끔하고 인테리어도 잘되어 있음. 맛이 있으며, 가격대비 상당히 만족스러운 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일본에선 코코이찌방밖에 못찾아 아쉽게도 아비꼬는 한국에서 먹어보게 되었다. 합리적인...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>제가 읽은 좋은 리뷰가 기대 이상이었습니다. 음식은 좋지만. 다양한 종류의 샐러드가...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11시 오픈인데 10시 50분 정도에도 이미 기다리는 분들이 있었습니다 ; 매장이 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>야미요밀 진짜 맛있긴 한데 4.3 이라니 ㄷㄷㄷ.. 물론 가성비 최고고 비건인데 맛...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우리는 우리의 사랑을 해! 브런치 도 정말 좋고 발코니에 앉아 이 너무 좋다. 내 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0  일본에선 코코이찌방밖에 못찾아 아쉽게도 아비꼬는 한국에서 먹어보게 되었다. 합리적인...      1\n",
       "1  제가 읽은 좋은 리뷰가 기대 이상이었습니다. 음식은 좋지만. 다양한 종류의 샐러드가...      0\n",
       "2  11시 오픈인데 10시 50분 정도에도 이미 기다리는 분들이 있었습니다 ; 매장이 ...      0\n",
       "3  야미요밀 진짜 맛있긴 한데 4.3 이라니 ㄷㄷㄷ.. 물론 가성비 최고고 비건인데 맛...      1\n",
       "4  우리는 우리의 사랑을 해! 브런치 도 정말 좋고 발코니에 앉아 이 너무 좋다. 내 ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review to wordlist \n",
    "\n",
    "- remove stop word\n",
    "- use okt tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from Word2VecUtility import Word2VecUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['별로', '임', '피스타치오', '랑', '에스프레소', '이다', '뭐', '먹다', '걍', '그저']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2VecUtility.review_to_wordlist(train_data['review'][1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make clean sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_clean_sentences = list(map(lambda x: Word2VecUtility.review_to_wordlist(x), train_data['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['과카', '몰리', '프라', '이즈', '더블', '더블', '버거', '아보카도', '버거'],\n",
       " ['별로',\n",
       "  '임',\n",
       "  '피스타치오',\n",
       "  '랑',\n",
       "  '에스프레소',\n",
       "  '이다',\n",
       "  '뭐',\n",
       "  '먹다',\n",
       "  '걍',\n",
       "  '그저',\n",
       "  '그렇다',\n",
       "  '식',\n",
       "  '감다',\n",
       "  '그렇다',\n",
       "  '맛',\n",
       "  '도',\n",
       "  '풍부하다',\n",
       "  '않다',\n",
       "  '근데',\n",
       "  '서비스',\n",
       "  '는',\n",
       "  '좋다'],\n",
       " ['삼선',\n",
       "  '이라고',\n",
       "  '붙다',\n",
       "  '메뉴',\n",
       "  '들',\n",
       "  '은',\n",
       "  '맛',\n",
       "  '이',\n",
       "  '나쁘다',\n",
       "  '않다',\n",
       "  '가격',\n",
       "  '이',\n",
       "  '비싸다',\n",
       "  '편이',\n",
       "  '고',\n",
       "  '일반',\n",
       "  '짜장면',\n",
       "  '이나',\n",
       "  '일반',\n",
       "  '짬뽕',\n",
       "  '늘다',\n",
       "  '냉동',\n",
       "  '재료',\n",
       "  '를',\n",
       "  '써다',\n",
       "  '별로',\n",
       "  '맛있다',\n",
       "  '느낌',\n",
       "  '이',\n",
       "  '들다',\n",
       "  '않다',\n",
       "  '점심때',\n",
       "  '항상',\n",
       "  '사람',\n",
       "  '이',\n",
       "  '많다',\n",
       "  '왜',\n",
       "  '사람',\n",
       "  '이',\n",
       "  '많다',\n",
       "  '이해',\n",
       "  '가',\n",
       "  '자다',\n",
       "  '안되다',\n",
       "  '곳',\n",
       "  '가운데',\n",
       "  '하나',\n",
       "  '이다'],\n",
       " ['이',\n",
       "  '지점',\n",
       "  '은',\n",
       "  '별로',\n",
       "  '붐비다',\n",
       "  '않다',\n",
       "  '좋다',\n",
       "  '커피',\n",
       "  '보다는',\n",
       "  '다른',\n",
       "  '차',\n",
       "  '와',\n",
       "  '간단하다',\n",
       "  '스낵',\n",
       "  '류',\n",
       "  '가',\n",
       "  '개인',\n",
       "  '적',\n",
       "  '으로는',\n",
       "  '좋다'],\n",
       " ['음식',\n",
       "  '도',\n",
       "  '깔끔하다',\n",
       "  '인테리어',\n",
       "  '도',\n",
       "  '잘',\n",
       "  '되어다',\n",
       "  '있다',\n",
       "  '맛',\n",
       "  '이',\n",
       "  '있다',\n",
       "  '가격',\n",
       "  '대비',\n",
       "  '상당하다',\n",
       "  '만족스럽다',\n",
       "  '음식',\n",
       "  '을',\n",
       "  '제',\n",
       "  '공함',\n",
       "  '사람',\n",
       "  '이',\n",
       "  '많다',\n",
       "  '좌석',\n",
       "  '이',\n",
       "  '복잡하다',\n",
       "  '빼다',\n",
       "  '괜찮다',\n",
       "  '주차',\n",
       "  '가',\n",
       "  '조금',\n",
       "  '불편하다'],\n",
       " ['사진',\n",
       "  '은',\n",
       "  '약간',\n",
       "  '타',\n",
       "  '버리다',\n",
       "  '토스트',\n",
       "  '랑',\n",
       "  '같이',\n",
       "  '먹기',\n",
       "  '위해',\n",
       "  '두다',\n",
       "  '마들렌',\n",
       "  '들',\n",
       "  '가로수길',\n",
       "  '골목',\n",
       "  '에',\n",
       "  '위치',\n",
       "  '한',\n",
       "  '테이크아웃',\n",
       "  '오다',\n",
       "  '마들렌',\n",
       "  '베이커리',\n",
       "  '다른',\n",
       "  '것',\n",
       "  '도',\n",
       "  '없다',\n",
       "  '건',\n",
       "  '아니다',\n",
       "  '마들렌',\n",
       "  '이',\n",
       "  '주요',\n",
       "  '메뉴',\n",
       "  '라',\n",
       "  '길',\n",
       "  '래',\n",
       "  '오',\n",
       "  '리지',\n",
       "  '널',\n",
       "  '글레이',\n",
       "  '즈',\n",
       "  '드',\n",
       "  '호',\n",
       "  '지',\n",
       "  '차',\n",
       "  '말차',\n",
       "  '골고루',\n",
       "  '주문',\n",
       "  '하다',\n",
       "  '호',\n",
       "  '지',\n",
       "  '차',\n",
       "  '와',\n",
       "  '오',\n",
       "  '리지',\n",
       "  '널',\n",
       "  '이외',\n",
       "  '엔',\n",
       "  '다',\n",
       "  '너무',\n",
       "  '달다',\n",
       "  '달다',\n",
       "  '꽤',\n",
       "  '나',\n",
       "  '좋아하다',\n",
       "  '남편',\n",
       "  '마저',\n",
       "  '한',\n",
       "  '입',\n",
       "  '먹다',\n",
       "  '아웃',\n",
       "  '전반',\n",
       "  '적',\n",
       "  '으로',\n",
       "  '안쪽',\n",
       "  '이',\n",
       "  '꽤',\n",
       "  '밀다',\n",
       "  '촉촉하다',\n",
       "  '느끼다',\n",
       "  '하다',\n",
       "  '겉',\n",
       "  '부분',\n",
       "  '은',\n",
       "  '그닥',\n",
       "  '바삭바삭하다',\n",
       "  '않다',\n",
       "  '글',\n",
       "  '라',\n",
       "  '세다',\n",
       "  '지나치다',\n",
       "  '달다',\n",
       "  '빵',\n",
       "  '의',\n",
       "  '기본',\n",
       "  '적',\n",
       "  '인',\n",
       "  '향',\n",
       "  '을',\n",
       "  '다',\n",
       "  '죽이다',\n",
       "  '느끼다',\n",
       "  '원래',\n",
       "  '레몬',\n",
       "  '향',\n",
       "  '과',\n",
       "  '버터',\n",
       "  '가',\n",
       "  '어우러지다',\n",
       "  '야하다',\n",
       "  '마들렌',\n",
       "  '의',\n",
       "  '기본',\n",
       "  '을',\n",
       "  '좋아하다',\n",
       "  '그냥',\n",
       "  '달기',\n",
       "  '만',\n",
       "  '하다',\n",
       "  '아이',\n",
       "  '들',\n",
       "  '일본',\n",
       "  '서',\n",
       "  '빵',\n",
       "  '배우다',\n",
       "  '한',\n",
       "  '데',\n",
       "  '마들렌',\n",
       "  '이',\n",
       "  '베이',\n",
       "  '킹',\n",
       "  '중',\n",
       "  '제일',\n",
       "  '초',\n",
       "  '급',\n",
       "  '단계',\n",
       "  '라',\n",
       "  '마들렌',\n",
       "  '전문',\n",
       "  '이라는',\n",
       "  '게',\n",
       "  '사실',\n",
       "  '쫌',\n",
       "  '괜찮다',\n",
       "  '베이커리',\n",
       "  '라면',\n",
       "  '여러',\n",
       "  '메뉴',\n",
       "  '중',\n",
       "  '마들렌',\n",
       "  '은',\n",
       "  '사이드',\n",
       "  '급',\n",
       "  '이다',\n",
       "  '보다',\n",
       "  '발효',\n",
       "  '도',\n",
       "  '필요없다',\n",
       "  '재료',\n",
       "  '배합',\n",
       "  '후',\n",
       "  '굽다',\n",
       "  '하다',\n",
       "  '되어다',\n",
       "  '진짜',\n",
       "  '자다',\n",
       "  '굽다',\n",
       "  '곳',\n",
       "  '들',\n",
       "  '과',\n",
       "  '비교',\n",
       "  '하다',\n",
       "  '애초',\n",
       "  '에',\n",
       "  '한국',\n",
       "  '엔',\n",
       "  '마들렌',\n",
       "  '을',\n",
       "  '먹다',\n",
       "  '수',\n",
       "  '있다',\n",
       "  '곳',\n",
       "  '이',\n",
       "  '흔',\n",
       "  '치',\n",
       "  '않다',\n",
       "  '치명',\n",
       "  '적',\n",
       "  '이지만',\n",
       "  '굳이',\n",
       "  '찾다',\n",
       "  '가다',\n",
       "  '먹다',\n",
       "  '집다',\n",
       "  '아니다',\n",
       "  '느낌',\n",
       "  '지나가다',\n",
       "  '입',\n",
       "  '이',\n",
       "  '심심하다',\n",
       "  '때',\n",
       "  '들리다',\n",
       "  '괜찮다'],\n",
       " ['생기다',\n",
       "  '얼마',\n",
       "  '안',\n",
       "  '돼다',\n",
       "  '인스타그램',\n",
       "  '에서',\n",
       "  '핫',\n",
       "  '한',\n",
       "  '곳',\n",
       "  '유명하다',\n",
       "  '메뉴',\n",
       "  '가',\n",
       "  '더치',\n",
       "  '아메리카노',\n",
       "  '아인슈페너',\n",
       "  '랑',\n",
       "  '따다',\n",
       "  '미정',\n",
       "  '원',\n",
       "  '이',\n",
       "  '있다'],\n",
       " ['인테리어',\n",
       "  '분위기',\n",
       "  '굳다',\n",
       "  '워낙',\n",
       "  '유명하다',\n",
       "  '점심',\n",
       "  '코스',\n",
       "  '답',\n",
       "  '게',\n",
       "  '가성',\n",
       "  '비',\n",
       "  '아주',\n",
       "  '좋다',\n",
       "  '\\n',\n",
       "  '요',\n",
       "  '리하나',\n",
       "  '하',\n",
       "  '나',\n",
       "  '디저트',\n",
       "  '까지',\n",
       "  '맛있다',\n",
       "  '\\n',\n",
       "  '야금야금',\n",
       "  '먹다',\n",
       "  '보다',\n",
       "  '돼지',\n",
       "  '가',\n",
       "  '되어다'],\n",
       " ['양', '이', '적다', '아쉽다', '맛있다', '생각', '보다', '계피', '향', '은', '많이', '나다'],\n",
       " ['또', '가다', '싶다']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 20:52:02,579 : INFO : collecting all words and their counts\n",
      "2019-11-20 20:52:02,580 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 20:52:02,727 : INFO : PROGRESS: at sentence #10000, processed 612749 words, keeping 18314 word types\n",
      "2019-11-20 20:52:02,818 : INFO : collected 21976 word types from a corpus of 940772 raw words and 15460 sentences\n",
      "2019-11-20 20:52:02,819 : INFO : Loading a fresh vocabulary\n",
      "2019-11-20 20:52:02,834 : INFO : effective_min_count=40 retains 2238 unique words (10% of original 21976, drops 19738)\n",
      "2019-11-20 20:52:02,835 : INFO : effective_min_count=40 leaves 842483 word corpus (89% of original 940772, drops 98289)\n",
      "2019-11-20 20:52:02,843 : INFO : deleting the raw counts dictionary of 21976 items\n",
      "2019-11-20 20:52:02,845 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2019-11-20 20:52:02,845 : INFO : downsampling leaves estimated 650703 word corpus (77.2% of prior 842483)\n",
      "2019-11-20 20:52:02,853 : INFO : estimated required memory for 2238 words and 300 dimensions: 6490200 bytes\n",
      "2019-11-20 20:52:02,854 : INFO : resetting layer weights\n",
      "2019-11-20 20:52:02,892 : INFO : training model with 4 workers on 2238 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-11-20 20:52:03,560 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 20:52:03,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 20:52:03,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 20:52:03,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 20:52:03,582 : INFO : EPOCH - 1 : training on 940772 raw words (650378 effective words) took 0.7s, 949000 effective words/s\n",
      "2019-11-20 20:52:04,320 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 20:52:04,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 20:52:04,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 20:52:04,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 20:52:04,327 : INFO : EPOCH - 2 : training on 940772 raw words (650740 effective words) took 0.7s, 879138 effective words/s\n",
      "2019-11-20 20:52:05,003 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 20:52:05,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 20:52:05,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 20:52:05,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 20:52:05,018 : INFO : EPOCH - 3 : training on 940772 raw words (650763 effective words) took 0.7s, 951931 effective words/s\n",
      "2019-11-20 20:52:05,720 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 20:52:05,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 20:52:05,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 20:52:05,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 20:52:05,745 : INFO : EPOCH - 4 : training on 940772 raw words (650777 effective words) took 0.7s, 902471 effective words/s\n",
      "2019-11-20 20:52:06,420 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 20:52:06,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 20:52:06,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 20:52:06,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 20:52:06,433 : INFO : EPOCH - 5 : training on 940772 raw words (650932 effective words) took 0.7s, 952867 effective words/s\n",
      "2019-11-20 20:52:06,434 : INFO : training on a 4703860 raw words (3253590 effective words) took 3.5s, 918796 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x19a2b8f7808>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라메터값 지정\n",
    "num_features = 300 # 문자 벡터 차원 수\n",
    "min_word_count = 40 # 최소 문자 수\n",
    "num_workers = 4 # 병렬 처리 스레드 수\n",
    "context = 10 # 문자열 창 크기\n",
    "downsampling = 1e-3 # 문자 빈도 수 Downsample\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "model = word2vec.Word2Vec(train_clean_sentences, \n",
    "                          workers=num_workers, \n",
    "                          size=num_features, \n",
    "                          min_count=min_word_count,\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 20:52:19,090 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-11-20 20:52:19,095 : INFO : saving Word2Vec object under 300features_40minwords_10text, separately None\n",
      "2019-11-20 20:52:19,097 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 20:52:19,098 : INFO : not storing attribute cum_table\n",
      "2019-11-20 20:52:19,157 : INFO : saved 300features_40minwords_10text\n"
     ]
    }
   ],
   "source": [
    "# 학습이 완료 되면 필요없는 메모리를 unload 시킨다.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model_name = '300features_40minwords_10text'\n",
    "# model_name = '300features_50minwords_20text'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Model\n",
    "\n",
    "\n",
    "#### 유사도가 없는 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 20:52:48,908 : WARNING : vectors for words {'코프당', '나는', '배가'} are not present in the model, ignoring these words\n",
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match('나는 너무 배가 코프당'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 20:53:08,475 : WARNING : vectors for words {'돈가네', '고기가'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"오늘 돈가네 너무 꿀맛 역시 고기가 최고\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가장 유사한 단어를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김치', 0.8137902617454529),\n",
       " ('양념', 0.7738972902297974),\n",
       " ('돼지', 0.758394181728363),\n",
       " ('돼지고기', 0.7510430812835693),\n",
       " ('소스', 0.7480180263519287),\n",
       " ('질', 0.7456825375556946),\n",
       " ('상태', 0.7222574353218079),\n",
       " ('닭고기', 0.7202495336532593),\n",
       " ('국물', 0.7186218500137329),\n",
       " ('부위', 0.717765212059021)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"고기\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('라떼', 0.8213275671005249),\n",
       " ('음료', 0.7946557998657227),\n",
       " ('원두', 0.7911272644996643),\n",
       " ('아메리카노', 0.7629014253616333),\n",
       " ('마시다', 0.694648265838623),\n",
       " ('드립', 0.6902950406074524),\n",
       " ('드립커피', 0.6846975088119507),\n",
       " ('핸드', 0.6743830442428589),\n",
       " ('아이스', 0.6723871827125549),\n",
       " ('마시기', 0.670570969581604)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"커피\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('정리', 0.6942277550697327),\n",
       " ('오지', 0.6578020453453064),\n",
       " ('인하다', 0.6554998755455017),\n",
       " ('돌아가다', 0.6549521684646606),\n",
       " ('가까이', 0.6464226245880127),\n",
       " ('발렛', 0.6460007429122925),\n",
       " ('돌다', 0.6377807855606079),\n",
       " ('불쾌하다', 0.6362069249153137),\n",
       " ('결코', 0.6355266571044922),\n",
       " ('지도', 0.63044273853302)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"치\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec으로 벡터화 한 단어를 t-SNE 를 통해 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 20:55:25,858 : INFO : loading Doc2Vec object from 300features_40minwords_10text\n",
      "2019-11-20 20:55:25,909 : INFO : loading wv recursively from 300features_40minwords_10text.wv.* with mmap=None\n",
      "2019-11-20 20:55:25,911 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-20 20:55:25,911 : INFO : loading vocabulary recursively from 300features_40minwords_10text.vocabulary.* with mmap=None\n",
      "2019-11-20 20:55:25,912 : INFO : loading trainables recursively from 300features_40minwords_10text.trainables.* with mmap=None\n",
      "2019-11-20 20:55:25,913 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-20 20:55:25,914 : INFO : loaded 300features_40minwords_10text\n",
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238\n",
      "[-0.10280141  0.0029384  -0.05596799 -0.08781978  0.06400931 -0.01224261\n",
      " -0.01507921 -0.01631313 -0.01152856 -0.02206977]\n"
     ]
    }
   ],
   "source": [
    "# 참고 https://stackoverflow.com/questions/43776572/visualise-word2vec-generated-from-gensim\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim \n",
    "import gensim.models as g\n",
    "\n",
    "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "model_name = '300features_40minwords_10text'\n",
    "model = g.Doc2Vec.load(model_name)\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]\n",
    "\n",
    "print(len(X))\n",
    "print(X[0][:10])\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "# 100개의 단어에 대해서만 시각화\n",
    "X_tsne = tsne.fit_transform(X[:100,:])\n",
    "# X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_tsne, index=vocab[:100], columns=['x', 'y'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과카</th>\n",
       "      <td>5.049896</td>\n",
       "      <td>3.911932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>몰리</th>\n",
       "      <td>4.992159</td>\n",
       "      <td>4.075616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>프라</th>\n",
       "      <td>4.658250</td>\n",
       "      <td>3.292644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이즈</th>\n",
       "      <td>5.003673</td>\n",
       "      <td>2.856261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>더블</th>\n",
       "      <td>5.331948</td>\n",
       "      <td>3.039095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>버거</th>\n",
       "      <td>6.470691</td>\n",
       "      <td>4.399792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아보카도</th>\n",
       "      <td>5.862441</td>\n",
       "      <td>3.858102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>별로</th>\n",
       "      <td>1.097762</td>\n",
       "      <td>-0.610586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>임</th>\n",
       "      <td>3.138421</td>\n",
       "      <td>-3.285877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>피스타치오</th>\n",
       "      <td>5.070419</td>\n",
       "      <td>1.680464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y\n",
       "과카     5.049896  3.911932\n",
       "몰리     4.992159  4.075616\n",
       "프라     4.658250  3.292644\n",
       "이즈     5.003673  2.856261\n",
       "더블     5.331948  3.039095\n",
       "버거     6.470691  4.399792\n",
       "아보카도   5.862441  3.858102\n",
       "별로     1.097762 -0.610586\n",
       "임      3.138421 -3.285877\n",
       "피스타치오  5.070419  1.680464"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    주어진 문장에서 단어 벡터의 평균을 구하는 함수\n",
    "    \"\"\"\n",
    "    # 속도를 위해 0으로 채운 배열로 초기화 한다.\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "\n",
    "    nwords = 0.\n",
    "    # Index2word는 모델의 사전에 있는 단어명을 담은 리스트이다.\n",
    "    # 속도를 위해 set 형태로 초기화 한다.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    # 루프를 돌며 모델 사전에 포함이 되는 단어라면 피처에 추가한다.\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # 결과를 단어수로 나누어 평균을 구한다.\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # 리뷰 단어 목록의 각각에 대한 평균 feature 벡터를 계산하고 \n",
    "    # 2D numpy 배열을 반환한다.\n",
    "    \n",
    "    # 카운터를 초기화 한다.\n",
    "    counter = 0.\n",
    "    # 속도를 위해 2D 넘파이 배열을 미리 할당한다.\n",
    "    reviewFeatureVecs = np.zeros(\n",
    "        (len(reviews),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for review in reviews:\n",
    "       # 매 1000개 리뷰마다 상태를 출력\n",
    "       if counter%1000. == 0.:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # 평균 피처 벡터를 만들기 위해 위에서 정의한 함수를 호출한다.\n",
    "       reviewFeatureVecs[int(counter)] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       # 카운터를 증가시킨다.\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티스레드로 4개의 워커를 사용해 처리한다.\n",
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    clean_reviews = Word2VecUtility.apply_by_multiprocessing(\\\n",
    "        reviews[\"review\"], Word2VecUtility.review_to_wordlist,\\\n",
    "        workers=4)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Data vector\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 15460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 15460\n",
      "Review 2000 of 15460\n",
      "Review 3000 of 15460\n",
      "Review 4000 of 15460\n",
      "Review 5000 of 15460\n",
      "Review 6000 of 15460\n",
      "Review 7000 of 15460\n",
      "Review 8000 of 15460\n",
      "Review 9000 of 15460\n",
      "Review 10000 of 15460\n",
      "Review 11000 of 15460\n",
      "Review 12000 of 15460\n",
      "Review 13000 of 15460\n",
      "Review 14000 of 15460\n",
      "Review 15000 of 15460\n",
      "Wall time: 58.6 s\n"
     ]
    }
   ],
   "source": [
    "%time trainDataVecs = getAvgFeatureVecs(\\\n",
    "    getCleanReviews(train_data), model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\skeks\\.conda\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 1718\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%time testDataVecs = getAvgFeatureVecs(\\\n",
    "        getCleanReviews(test_data), model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators = 100, n_jobs = -1, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Word to vector Nan value\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15460"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(trainDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge score field\n",
    "\n",
    "train_df['score'] = train_data['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na value\n",
    "\n",
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word2vec_data\n",
    "train_word2vec = df1.drop(['score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%time forest = forest.fit(word2vec_train_data, train_df['score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "%time score = np.mean(cross_val_score(\\\n",
    "    forest, df2, \\\n",
    "    df1['score'], cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220375075760525"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Word to vector Nan value(test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['score'] = test_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word2vec = test_df.drop(['score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = forest.predict(test_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_result = np.array(test_df['score'].values)\n",
    "correct_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209715639810427"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = [1 if predict_result[i] == correct_result[i] else 0 for i in range(len(real))]\n",
    "\n",
    "sum(test_prediction) / len(test_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}